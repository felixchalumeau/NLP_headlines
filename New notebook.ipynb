{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "considerable-protest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "departmental-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import tensorflow\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "\n",
    "# Number of epochs\n",
    "epochs = 10\n",
    "\n",
    "# Proportion of training data for train compared to dev\n",
    "train_proportion = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "multiple-option",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original</th>\n",
       "      <th>edit</th>\n",
       "      <th>grades</th>\n",
       "      <th>meanGrade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14530</td>\n",
       "      <td>France is ‘ hunting down its citizens who join...</td>\n",
       "      <td>twins</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13034</td>\n",
       "      <td>Pentagon claims 2,000 % increase in Russian tr...</td>\n",
       "      <td>bowling</td>\n",
       "      <td>33110</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8731</td>\n",
       "      <td>Iceland PM Calls Snap Vote as Pedophile Furor ...</td>\n",
       "      <td>party</td>\n",
       "      <td>22100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>In an apparent first , Iran and Israel &lt;engage...</td>\n",
       "      <td>slap</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6164</td>\n",
       "      <td>Trump was told weeks ago that Flynn misled &lt;Vi...</td>\n",
       "      <td>school</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           original     edit  grades  \\\n",
       "0  14530  France is ‘ hunting down its citizens who join...    twins   10000   \n",
       "1  13034  Pentagon claims 2,000 % increase in Russian tr...  bowling   33110   \n",
       "2   8731  Iceland PM Calls Snap Vote as Pedophile Furor ...    party   22100   \n",
       "3     76  In an apparent first , Iran and Israel <engage...     slap   20000   \n",
       "4   6164  Trump was told weeks ago that Flynn misled <Vi...   school       0   \n",
       "\n",
       "   meanGrade  \n",
       "0        0.2  \n",
       "1        1.6  \n",
       "2        1.0  \n",
       "3        0.4  \n",
       "4        0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the data\n",
    "\n",
    "train_df = pd.read_csv('data/task-1/train.csv')\n",
    "test_df = pd.read_csv('data/task-1/dev.csv')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "theoretical-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, device):\n",
    "        super(Network, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2label = nn.Linear(hidden_dim * 2, 1)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\n",
    "        return torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device), \\\n",
    "               torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # TODO\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "medical-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define our training loop\n",
    "def train(train_iter, dev_iter, model, number_epoch):\n",
    "    \"\"\"\n",
    "    Training loop for the model, which calls on eval to evaluate after each epoch\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    print(\"Training model.\")\n",
    "\n",
    "    for epoch in range(1, number_epoch+1):\n",
    "\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_sse = 0\n",
    "        no_observations = 0  # Observations used for training so far\n",
    "\n",
    "        for batch in train_iter:\n",
    "\n",
    "            feature, target = batch\n",
    "\n",
    "            feature, target = feature.to(device), target.to(device)\n",
    "\n",
    "            # for RNN:\n",
    "            model.batch_size = target.shape[0]\n",
    "            no_observations = no_observations + target.shape[0]\n",
    "            model.hidden = model.init_hidden()\n",
    "\n",
    "            predictions = model(feature).squeeze(1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = loss_fn(predictions, target)\n",
    "\n",
    "            sse, __ = model_performance(predictions.detach().cpu().numpy(), target.detach().cpu().numpy())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()*target.shape[0]\n",
    "            epoch_sse += sse\n",
    "\n",
    "        valid_loss, valid_mse, __, __ = eval(dev_iter, model)\n",
    "\n",
    "        epoch_loss, epoch_mse = epoch_loss / no_observations, epoch_sse / no_observations\n",
    "        print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train MSE: {epoch_mse:.2f} | Train RMSE: {epoch_mse**0.5:.2f} | \\\n",
    "        Val. Loss: {valid_loss:.2f} | Val. MSE: {valid_mse:.2f} |  Val. RMSE: {valid_mse**0.5:.2f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ready-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We evaluate performance on our dev set\n",
    "def eval(data_iter, model):\n",
    "    \"\"\"\n",
    "    Evaluating model performance on the dev set\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_sse = 0\n",
    "    pred_all = []\n",
    "    trg_all = []\n",
    "    no_observations = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_iter:\n",
    "            feature, target = batch\n",
    "\n",
    "            feature, target = feature.to(device), target.to(device)\n",
    "\n",
    "            # for RNN:\n",
    "            model.batch_size = target.shape[0]\n",
    "            no_observations = no_observations + target.shape[0]\n",
    "            model.hidden = model.init_hidden()\n",
    "\n",
    "            predictions = model(feature).squeeze(1)\n",
    "            loss = loss_fn(predictions, target)\n",
    "\n",
    "            # We get the mse\n",
    "            pred, trg = predictions.detach().cpu().numpy(), target.detach().cpu().numpy()\n",
    "            sse, __ = model_performance(pred, trg)\n",
    "\n",
    "            epoch_loss += loss.item()*target.shape[0]\n",
    "            epoch_sse += sse\n",
    "            pred_all.extend(pred)\n",
    "            trg_all.extend(trg)\n",
    "\n",
    "    return epoch_loss/no_observations, epoch_sse/no_observations, np.array(pred_all), np.array(trg_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "selected-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How we print the model performance\n",
    "def model_performance(output, target, print_output=False):\n",
    "    \"\"\"\n",
    "    Returns SSE and MSE per batch (printing the MSE and the RMSE)\n",
    "    \"\"\"\n",
    "\n",
    "    sq_error = (output - target)**2\n",
    "\n",
    "    sse = np.sum(sq_error)\n",
    "    mse = np.mean(sq_error)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    if print_output:\n",
    "        print(f'| MSE: {mse:.2f} | RMSE: {rmse:.2f} |')\n",
    "\n",
    "    return sse, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "interpreted-lloyd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_padd(batch):\n",
    "    '''\n",
    "    We add padding to our minibatches and create tensors for our model\n",
    "    '''\n",
    "\n",
    "    batch_labels = [l for f, l in batch]\n",
    "    batch_features = [f for f, l in batch]\n",
    "\n",
    "    batch_features_len = [len(f) for f, l in batch]\n",
    "\n",
    "    seq_tensor = torch.zeros((len(batch), max(batch_features_len))).long()\n",
    "\n",
    "    for idx, (seq, seqlen) in enumerate(zip(batch_features, batch_features_len)):\n",
    "        seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\n",
    "\n",
    "    batch_labels = torch.FloatTensor(batch_labels)\n",
    "\n",
    "    return seq_tensor, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "radical-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "def headlines2vec(tokenizer, headlines):    \n",
    "    \"\"\"\n",
    "    Function that applies a tokenizer to the \n",
    "    headlines and padds the output to get the expected dimension\n",
    "    \"\"\"\n",
    "    \n",
    "    ret = np.array(tokenizer(headlines, padding = True, add_special_tokens = False)['input_ids'])\n",
    "    return ret\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "short-progress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialised.\n",
      "[[ 2605  2003  1520 ...     0     0     0]\n",
      " [20864  4447  1016 ...     0     0     0]\n",
      " [10399  7610  4455 ...     0     0     0]\n",
      " ...\n",
      " [ 8592  2240 11485 ...     0     0     0]\n",
      " [ 3996  2610  5690 ...     0     0     0]\n",
      " [ 2182  1005  1055 ...     0     0     0]]\n",
      "Embedding done.\n",
      "Dataloaders created.\n",
      "Training model.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-2f418eedc00b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-381b19b99820>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_iter, dev_iter, model, number_epoch)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mno_observations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m  \u001b[0;31m# Observations used for training so far\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-55-27741e37c14f>\u001b[0m in \u001b[0;36mcollate_fn_padd\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      4\u001b[0m     '''\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mbatch_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-27741e37c14f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m     '''\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mbatch_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## Approach 1 code, using functions defined above:\n",
    "\n",
    "# We set our training data and test data\n",
    "training_data = train_df['original']\n",
    "test_data = test_df['original']\n",
    "\n",
    "\n",
    "\n",
    "INPUT_DIM = 20 #20 words max in a headline\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "model = Network(INPUT_DIM, 50, BATCH_SIZE, device)\n",
    "print(\"Model initialised.\")\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# EMBEDDING\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "train_dataset = headlines2vec(tokenizer, training_data.tolist()) #TOLIST AVOIDABLE ?\n",
    "\n",
    "print(train_dataset) #MEAN GRADE !!!\n",
    "\n",
    "dev_dataset = headlines2vec(tokenizer, test_data.tolist())\n",
    "\n",
    "print(\"Embedding done.\")\n",
    "\n",
    "\n",
    "# DATA LOADERS\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
    "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
    "\n",
    "print(\"Dataloaders created.\")\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train(train_loader, dev_loader, model, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-sharing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
