{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "nlp_approach2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZRX7kKfFjEV"
      },
      "source": [
        "# import libraries\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from torch.utils.data import Dataset, random_split\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import codecs"
      ],
      "id": "0ZRX7kKfFjEV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk4c4HGAFjEX"
      },
      "source": [
        "# set random seed and device\n",
        "\n",
        "SEED = 1\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
      ],
      "id": "Zk4c4HGAFjEX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btt9zp8CicR7"
      },
      "source": [
        "### Define useful functions\r\n",
        "We had to slightly modify train and eval to adapt to the forward pass of our model."
      ],
      "id": "btt9zp8CicR7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EmwQEcTNWSI"
      },
      "source": [
        "# We define our training loop\n",
        "def train(train_iter, dev_iter, model, number_epoch):\n",
        "    \"\"\"\n",
        "    Training loop for the model, which calls on eval to evaluate after each epoch\n",
        "    \"\"\"\n",
        "\n",
        "    \n",
        "    print(\"Training model.\")\n",
        "\n",
        "    for epoch in range(1, number_epoch+1):\n",
        "\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        epoch_sse = 0\n",
        "        no_observations = 0  # Observations used for training so far\n",
        "\n",
        "        for batch in train_iter:\n",
        "\n",
        "            input_sent, input_feat, target = batch\n",
        "\n",
        "            input_sent, input_feat, target = input_sent.to(device), input_feat.to(device), target.to(device)\n",
        "\n",
        "            model.batch_size = target.shape[0]\n",
        "            no_observations = no_observations + target.shape[0]\n",
        "\n",
        "            predictions = model(input_sent, input_feat).squeeze(1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss = loss_fn(predictions, target)\n",
        "\n",
        "            sse, __ = model_performance(predictions.detach().cpu().numpy(), target.detach().cpu().numpy())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()*target.shape[0]\n",
        "            epoch_sse += sse\n",
        "\n",
        "        valid_loss, valid_mse, __, __ = eval(dev_iter, model)\n",
        "\n",
        "        epoch_loss, epoch_mse = epoch_loss / no_observations, epoch_sse / no_observations\n",
        "        print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.3f} | Train MSE: {epoch_mse:.3f} | Train RMSE: {epoch_mse**0.5:.3f} | \\\n",
        "        Val. Loss: {valid_loss:.3f} | Val. MSE: {valid_mse:.3f} |  Val. RMSE: {valid_mse**0.5:.3f} |')"
      ],
      "id": "9EmwQEcTNWSI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6e85rXWNayn"
      },
      "source": [
        "# We evaluate performance on our dev set\n",
        "def eval(data_iter, model):\n",
        "    \"\"\"\n",
        "    Evaluating model performance on the dev set\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_sse = 0\n",
        "    pred_all = []\n",
        "    trg_all = []\n",
        "    no_observations = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_iter:\n",
        "            input_sent, input_feat, target = batch\n",
        "\n",
        "            input_sent, input_feat, target = input_sent.to(device), input_feat.to(device), target.to(device)\n",
        "\n",
        "            model.batch_size = target.shape[0]\n",
        "            no_observations = no_observations + target.shape[0]\n",
        "\n",
        "            predictions = model(input_sent, input_feat).squeeze(1)\n",
        "            loss = loss_fn(predictions, target)\n",
        "\n",
        "            # We get the mse\n",
        "            pred, trg = predictions.detach().cpu().numpy(), target.detach().cpu().numpy()\n",
        "            sse, __ = model_performance(pred, trg)\n",
        "\n",
        "            epoch_loss += loss.item()*target.shape[0]\n",
        "            epoch_sse += sse\n",
        "            pred_all.extend(pred)\n",
        "            trg_all.extend(trg)\n",
        "\n",
        "    return epoch_loss/no_observations, epoch_sse/no_observations, np.array(pred_all), np.array(trg_all)"
      ],
      "id": "u6e85rXWNayn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pePEqvJEFjEZ"
      },
      "source": [
        "# How we print the model performance\n",
        "def model_performance(output, target, print_output=False):\n",
        "    \"\"\"\n",
        "    Returns SSE and MSE per batch (printing the MSE and the RMSE)\n",
        "    \"\"\"\n",
        "\n",
        "    sq_error = (output - target)**2\n",
        "\n",
        "    sse = np.sum(sq_error)\n",
        "    mse = np.mean(sq_error)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    if print_output:\n",
        "        print(f'| MSE: {mse:.2f} | RMSE: {rmse:.2f} |')\n",
        "\n",
        "    return sse, mse"
      ],
      "id": "pePEqvJEFjEZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwO3OpF6FjEZ"
      },
      "source": [
        "def create_vocab(data):\n",
        "    \"\"\"\n",
        "    Creating a corpus of all the tokens used\n",
        "    \"\"\"\n",
        "    tokenized_corpus = [] # Let us put the tokenized corpus in a list\n",
        "\n",
        "    for sentence in data:\n",
        "\n",
        "        tokenized_sentence = []\n",
        "\n",
        "        for token in sentence.split(' '): # simplest split is\n",
        "\n",
        "            tokenized_sentence.append(token)\n",
        "\n",
        "        tokenized_corpus.append(tokenized_sentence)\n",
        "\n",
        "    # Create single list of all vocabulary\n",
        "    vocabulary = []  # Let us put all the tokens (mostly words) appearing in the vocabulary in a list\n",
        "\n",
        "    for sentence in tokenized_corpus:\n",
        "\n",
        "        for token in sentence:\n",
        "\n",
        "            if token not in vocabulary:\n",
        "\n",
        "                if True:\n",
        "                    vocabulary.append(token)\n",
        "\n",
        "    return vocabulary, tokenized_corpus"
      ],
      "id": "GwO3OpF6FjEZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9IzMIcHFvxM"
      },
      "source": [
        "# Approach 2"
      ],
      "id": "C9IzMIcHFvxM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7byS8Osi4t3"
      },
      "source": [
        "# load datasets\r\n",
        "\r\n",
        "train_df = pd.read_csv('train.csv')\r\n",
        "dev_df = pd.read_csv('dev.csv')"
      ],
      "id": "l7byS8Osi4t3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5NjwEtQFjEZ"
      },
      "source": [
        "## a. TF-IDF code (given) and baseline"
      ],
      "id": "e5NjwEtQFjEZ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3degz_y-FjEa",
        "outputId": "97641768-7361-43ca-b4c7-730b4e545c92"
      },
      "source": [
        "train_proportion = 0.8\n",
        "train_and_dev = train_df['edit']\n",
        "\n",
        "training_data, dev_data, training_y, dev_y = train_test_split(train_df['edit'], train_df['meanGrade'],\n",
        "                                                                        test_size=(1-train_proportion),\n",
        "                                                                        random_state=42)\n",
        "\n",
        "# We train a Tf-idf model\n",
        "count_vect = CountVectorizer(stop_words='english')\n",
        "train_counts = count_vect.fit_transform(training_data)\n",
        "transformer = TfidfTransformer().fit(train_counts)\n",
        "train_counts = transformer.transform(train_counts)\n",
        "regression_model = LinearRegression().fit(train_counts, training_y)\n",
        "\n",
        "# Train predictions\n",
        "predicted_train = regression_model.predict(train_counts)\n",
        "\n",
        "# Calculate Tf-idf using train and dev, and validate model on dev:\n",
        "test_and_test_counts = count_vect.transform(train_and_dev)\n",
        "transformer = TfidfTransformer().fit(test_and_test_counts)\n",
        "\n",
        "test_counts = count_vect.transform(dev_data)\n",
        "\n",
        "test_counts = transformer.transform(test_counts)\n",
        "\n",
        "# Dev predictions\n",
        "predicted = regression_model.predict(test_counts)\n",
        "\n",
        "# We run the evaluation:\n",
        "print(\"\\nTrain performance:\")\n",
        "sse, mse = model_performance(predicted_train, training_y, True)\n",
        "\n",
        "print(\"\\nDev performance:\")\n",
        "sse, mse = model_performance(predicted, dev_y, True)"
      ],
      "id": "3degz_y-FjEa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train performance:\n",
            "| MSE: 0.13 | RMSE: 0.37 |\n",
            "\n",
            "Dev performance:\n",
            "| MSE: 0.36 | RMSE: 0.60 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6oS9rOoFjEa",
        "outputId": "470a7d4c-f576-4613-e5ea-eb5bd4cb2c7a"
      },
      "source": [
        "# baseline for the task\n",
        "\n",
        "pred_baseline = torch.zeros(len(dev_y)) + np.mean(training_y)\n",
        "print(\"\\nBaseline performance:\")\n",
        "sse, mse = model_performance(pred_baseline, dev_y, True)"
      ],
      "id": "Z6oS9rOoFjEa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Baseline performance:\n",
            "| MSE: 0.34 | RMSE: 0.58 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_qUgPYzpMPB"
      },
      "source": [
        "## b. BERT-like model\n",
        "First attempt at training a BERT-like transformer model. We thought we would create a model from scratch using the given libraries, train it on a smaller but dedicated dataset, and implement it in place of BERT. We went for a RoBERTa-like model. All elements of the model are identified with the suffix \"_2b\"\n",
        "\n",
        "Largely inspired by https://towardsdatascience.com/transformers-retraining-roberta-base-using-the-roberta-mlm-procedure-7422160d5764 \n",
        "\n",
        "With finally had issues and couldn't achieve what we wanted, thus, we set the bool attempt_bert to False, so this lines of code do not run but you can see what we tried."
      ],
      "id": "Q_qUgPYzpMPB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Phgne8DdFjEf",
        "outputId": "921fe468-d4ca-4991-d924-523f810bb7b6"
      },
      "source": [
        "# mount google drive to work in colab\n",
        "attempt_bert = False\n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "!mkdir \"/content/drive/My Drive/abc/aBERTc2\"\n",
        "\"\"\"\n",
        "print(\" \")"
      ],
      "id": "Phgne8DdFjEf",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K9E4O8ZFjEf"
      },
      "source": [
        "# extract txt from original csv dataset\n",
        "# commented out as only needed the first time\n",
        "\n",
        "# import pandas as pd\n",
        "# abcnews = pd.read_csv('/content/drive/My Drive/abc/abcnews.csv')\n",
        "\n",
        "# with open(\"/content/drive/My Drive/abc/abcheads.txt\", \"a\") as file:\n",
        "#   for line in abcnews['headline_text']:\n",
        "#     line += \"\\n\"\n",
        "#     file.write(line)"
      ],
      "id": "9K9E4O8ZFjEf",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDRIbRlDFjEf"
      },
      "source": [
        "# import premade tokenizer (byte-level BPE)\n",
        "if attempt_bert:\n",
        "    from transformers import RobertaTokenizer\n",
        "    from transformers import LineByLineTextDataset\n",
        "    from transformers import DataCollatorForLanguageModeling\n",
        "    from transformers import RobertaConfig, RobertaForMaskedLM\n",
        "    from transformers import Trainer, TrainingArguments\n",
        "    from transformers import pipeline\n",
        "\n",
        "    tokenizer_2b = RobertaTokenizer.from_pretrained('roberta-base')"
      ],
      "id": "jDRIbRlDFjEf",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1K6SeeQFjEg"
      },
      "source": [
        "# prepare txt dataset with tokenizer\n",
        "if attempt_bert:\n",
        "    dataset_2b = LineByLineTextDataset(\n",
        "        tokenizer=tokenizer_2b,\n",
        "        file_path=\"/content/drive/My Drive/abc/abcheads.txt\",\n",
        "        block_size=128,\n",
        "    )"
      ],
      "id": "b1K6SeeQFjEg",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vZUTcKIFjEg"
      },
      "source": [
        "# prepare data collator (speeds up things, not sure what)\n",
        "if attempt_bert:\n",
        "    data_collator_2b = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer_2b, mlm=True, mlm_probability=0.15\n",
        "    )"
      ],
      "id": "4vZUTcKIFjEg",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjdHW3CVFjEg"
      },
      "source": [
        "# create Roberta model from scratch, just prepare config\n",
        "if attempt_bert:\n",
        "    config_2b = RobertaConfig(\n",
        "        vocab_size=52_000,\n",
        "        max_position_embeddings=514,\n",
        "        num_attention_heads=12,\n",
        "        num_hidden_layers=6,\n",
        "        type_vocab_size=1,\n",
        "    )\n",
        "\n",
        "    model_2b = RobertaForMaskedLM(config=config_2b)"
      ],
      "id": "XjdHW3CVFjEg",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whg0C5JvFjEh"
      },
      "source": [
        "# set up training configurations\n",
        "if attempt_bert:\n",
        "    training_args_2b = TrainingArguments(\n",
        "        output_dir=\"/content/drive/My Drive/abc/aBERTc2\",\n",
        "        overwrite_output_dir=True,\n",
        "        num_train_epochs=1,\n",
        "        per_device_train_batch_size=64,\n",
        "        save_steps=10_000,\n",
        "        save_total_limit=2,\n",
        "        seed=1\n",
        "    )\n",
        "\n",
        "    trainer_2b = Trainer(\n",
        "        model=model_2b,\n",
        "        args=training_args_2b,\n",
        "        data_collator=data_collator_2b,\n",
        "        train_dataset=dataset_2b\n",
        "    )"
      ],
      "id": "whg0C5JvFjEh",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g632xY6AFjEh"
      },
      "source": [
        "# verify model parameters ~ 84M\n",
        "if attempt_bert:\n",
        "    model_2b.num_parameters()"
      ],
      "id": "g632xY6AFjEh",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYZlmOT1FjEi"
      },
      "source": [
        "# train and save trained model\n",
        "if attempt_bert:\n",
        "    trainer_2b.train()\n",
        "    trainer_2b.save_model(\"/content/drive/My Drive/abc/aBERTc2\")"
      ],
      "id": "tYZlmOT1FjEi",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cccb05fSFjEj"
      },
      "source": [
        "# sanity check on model performance\n",
        "if attempt_bert:\n",
        "    fill_mask = pipeline(\n",
        "        \"fill-mask\",\n",
        "        model=\"/content/drive/My Drive/abc/aBERTc2\",\n",
        "        tokenizer=\"roberta-base\"\n",
        "    )\n",
        "    fill_mask(\"Send these <mask> back!\")"
      ],
      "id": "Cccb05fSFjEj",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va8hUPFeFjEk"
      },
      "source": [
        "At this point, we wanted to use what we did in approach by replacing the previous pretrained BERT with this RoBERTa model but we had issue that we couldn't fix."
      ],
      "id": "va8hUPFeFjEk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkX8TYapFjEk"
      },
      "source": [
        "## c. Our final choice for approach 2 : FFN with word embeddings and engineered features\n",
        "As second attempt we tried to combine a simple embedding with engineered features. We used all the words from the original headline + the edited word, stripped of its punctuation. Pass them to an embedding layer than to a linear layer with a relu activation function. We also use engineered features extracted from the headlines, pass them through two layers and concatenated both results into a single array than when two pass through two layers. We added drop out at every step to avoid overfitting."
      ],
      "id": "pkX8TYapFjEk"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc8sTZ1h2xpv"
      },
      "source": [
        "# load datasets\r\n",
        "\r\n",
        "train_df = pd.read_csv('train.csv')\r\n",
        "dev_df = pd.read_csv('dev.csv')"
      ],
      "id": "Vc8sTZ1h2xpv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1avTLWzXxRa1"
      },
      "source": [
        "#### Define useful functions"
      ],
      "id": "1avTLWzXxRa1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saoHkr4sFjEk"
      },
      "source": [
        "# recreate tok_corpus, word2idx and related functions, with punctuation removal\n",
        "\n",
        "import re\n",
        "re_punctuation_string = '[\\s,/.\\'<>]'\n",
        "\n",
        "def get_tokenized_corpus(corpus):\n",
        "  tokenized_corpus = []\n",
        "\n",
        "  for sentence in corpus:\n",
        "    tokenized_sentence = []\n",
        "    for token in re.split(' ', sentence): \n",
        "      tokenized_sentence.append(token)\n",
        "    tokenized_corpus.append(tokenized_sentence)\n",
        " \n",
        "  return tokenized_corpus\n",
        "\n",
        "\n",
        "def get_word2idx(tokenized_corpus):\n",
        "  vocabulary = []\n",
        "  for sentence in tokenized_corpus:\n",
        "    for token in sentence:\n",
        "        if token not in vocabulary:\n",
        "            vocabulary.append(token)\n",
        "  \n",
        "  word2idx = {w: idx+1 for (idx, w) in enumerate(vocabulary)}\n",
        "  word2idx['<pad>'] = 0\n",
        "  \n",
        "  return word2idx\n",
        "\n",
        "\n",
        "def get_model_inputs(tokenized_corpus, word2idx):\n",
        "  vectorized_sents = [[word2idx[tok] for tok in sent if tok in word2idx] for sent in tokenized_corpus]\n",
        "  sent_lengths = [len(sent) for sent in vectorized_sents]\n",
        "  max_len = max(sent_lengths)\n",
        "  sent_tensor = torch.zeros((len(vectorized_sents), max_len)).long()\n",
        "  for idx, (sent, sentlen) in enumerate(zip(vectorized_sents, sent_lengths)):\n",
        "    sent_tensor[idx, :sentlen] = torch.LongTensor(sent)\n",
        "  return sent_tensor"
      ],
      "id": "saoHkr4sFjEk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSjy0JqmpbxX"
      },
      "source": [
        "punctuations = '''!()-[]{};:‘’\"\\,.?@#$%^&*_~'''\r\n",
        "# sorry for the words...\r\n",
        "sex_words = [\"orgy\", \"dick\", \"suck\", \"underwear\", \"sex\", \"sexual\", \"massage\", \"flirt\", \"kiss\", \"ass\", \"penis\"]\r\n",
        "\r\n",
        "def create_engineered_features(input_df, punctuations, sex_words):\r\n",
        "    \"\"\"\r\n",
        "    Take a dataset as input, create eleven engineered features and output the modified dataset.\r\n",
        "    \"\"\"\r\n",
        "    input_df[\"lower_case\"] = input_df.apply(\r\n",
        "            lambda x: x[\"original\"].lower(), axis=1\r\n",
        "        )\r\n",
        "    input_df[\"edit_lower\"] = input_df.apply(\r\n",
        "            lambda x: x[\"edit\"].lower(), axis=1\r\n",
        "        )\r\n",
        "    input_df[\"nb_words\"] = input_df.apply(\r\n",
        "            lambda x: len(x[\"lower_case\"].split(\" \")), axis=1\r\n",
        "        )\r\n",
        "    input_df[\"nb_caracters\"] = input_df.apply(\r\n",
        "            lambda x: len(x[\"lower_case\"]), axis=1\r\n",
        "        )\r\n",
        "    input_df[\"nb_ponctuations\"] = input_df.apply(\r\n",
        "            lambda x: sum([1 if char in punctuations else 0 for char in x[\"lower_case\"]]), axis=1\r\n",
        "        )\r\n",
        "    input_df[\"edit_position\"] = input_df.apply(\r\n",
        "            lambda x: x[\"lower_case\"].find(\"<\"), axis=1\r\n",
        "        )\r\n",
        "    input_df[\"edit_rel_position\"] = input_df.apply(\r\n",
        "            lambda x: x[\"edit_position\"]/x[\"nb_caracters\"], axis=1\r\n",
        "        )\r\n",
        "    input_df[\"len_edit\"] = input_df.apply(\r\n",
        "            lambda x: len(x[\"edit_lower\"]), axis=1\r\n",
        "        )\r\n",
        "    # i need trump\r\n",
        "    input_df[\"trump_in_original\"] = input_df.apply(\r\n",
        "            lambda x: float(x[\"lower_case\"].find(\"trump\") != -1), axis=1\r\n",
        "        )\r\n",
        "    input_df[\"trump_in_edit\"] = input_df.apply(\r\n",
        "            lambda x: float(x[\"edit_lower\"].find(\"trump\") != -1), axis=1\r\n",
        "        )\r\n",
        "\r\n",
        "    # i need hair\r\n",
        "    input_df[\"hair_in_original\"] = input_df.apply(\r\n",
        "            lambda x: float(x[\"lower_case\"].find(\"hair\") != -1), axis=1\r\n",
        "        )\r\n",
        "    input_df[\"hair_in_edit\"] = input_df.apply(\r\n",
        "            lambda x: float(x[\"edit_lower\"].find(\"hair\") != -1), axis=1\r\n",
        "        )\r\n",
        "    input_df[\"sex_in_edit\"] = input_df.apply(\r\n",
        "            lambda x: float(x[\"edit_lower\"] in sex_words), axis=1\r\n",
        "        )\r\n",
        "\r\n",
        "    return input_df"
      ],
      "id": "PSjy0JqmpbxX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJvuhiNsxXO_"
      },
      "source": [
        "#### Prepare the training set"
      ],
      "id": "tJvuhiNsxXO_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7uxtxdRkZog"
      },
      "source": [
        "##### Prepare the headline to be embedded"
      ],
      "id": "k7uxtxdRkZog"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "027WotZjpGPg"
      },
      "source": [
        "# prepare for the embedding part\r\n",
        "tokenized_corpus = get_tokenized_corpus(train_df[\"original\"].str.cat(train_df[\"edit\"], sep=\" \").tolist())\r\n",
        "word2idx = get_word2idx(tokenized_corpus)\r\n",
        "train_sentence = get_model_inputs(tokenized_corpus, word2idx)"
      ],
      "id": "027WotZjpGPg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1Q7oeZ4p6zR"
      },
      "source": [
        "columns = [\r\n",
        "    \"nb_words\", \"nb_caracters\", \"nb_ponctuations\", \"edit_position\",\r\n",
        "    \"edit_rel_position\", \"len_edit\", \"trump_in_original\", \"trump_in_edit\",\r\n",
        "    \"hair_in_original\", \"hair_in_edit\", \"sex_in_edit\"\r\n",
        "]"
      ],
      "id": "k1Q7oeZ4p6zR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUJ8-ivikgeg"
      },
      "source": [
        "##### Create and scale the engineered features"
      ],
      "id": "eUJ8-ivikgeg"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7osOZPDppI_T"
      },
      "source": [
        "# prepare the engineered features\r\n",
        "train_df = create_engineered_features(train_df, punctuations, sex_words)\r\n",
        "    \r\n",
        "train_features = train_df[columns].values\r\n",
        "train_labels = train_df.meanGrade.values\r\n",
        "\r\n",
        "scaler = StandardScaler()\r\n",
        "scaler.fit(train_features)\r\n",
        "train_features = scaler.transform(train_features)"
      ],
      "id": "7osOZPDppI_T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1wzxVQmxfP1"
      },
      "source": [
        "#### Prepare the validation set in the same way"
      ],
      "id": "d1wzxVQmxfP1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vbv-Tutoxd72"
      },
      "source": [
        "# prepare validation dataset\r\n",
        "dev_tokenized_corpus = get_tokenized_corpus(dev_df[\"original\"].str.cat(dev_df[\"edit\"], sep=\" \").tolist())\r\n",
        "dev_sentence = get_model_inputs(dev_tokenized_corpus, word2idx)\r\n",
        "\r\n",
        "dev_df = create_engineered_features(dev_df, punctuations, sex_words)\r\n",
        "dev_features = dev_df[columns].values\r\n",
        "dev_labels = dev_df['meanGrade'].values\r\n",
        "\r\n",
        "dev_features = scaler.transform(dev_features)"
      ],
      "id": "Vbv-Tutoxd72",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd5n9aMKyZpy"
      },
      "source": [
        "#### Create the dataloaders"
      ],
      "id": "jd5n9aMKyZpy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN5G5Iz2yYZJ",
        "outputId": "56bbbe7c-a5ad-470f-a741-b0736d574f47"
      },
      "source": [
        "# create dataloaders\r\n",
        "\r\n",
        "BATCH_SIZE = 32\r\n",
        "\r\n",
        "train_features = torch.tensor(train_features, dtype=torch.float32)\r\n",
        "train_labels = torch.tensor(train_labels, dtype=torch.float32)\r\n",
        "\r\n",
        "dev_features = torch.tensor(dev_features, dtype=torch.float32)\r\n",
        "dev_labels = torch.tensor(dev_labels, dtype=torch.float32)\r\n",
        "\r\n",
        "train_data = torch.utils.data.TensorDataset(train_sentence, train_features, train_labels)\r\n",
        "dev_data = torch.utils.data.TensorDataset(dev_sentence, dev_features, dev_labels)\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE)\r\n",
        "validation_loader = torch.utils.data.DataLoader(dev_data, shuffle=False, batch_size=BATCH_SIZE)\r\n",
        "\r\n",
        "print(\"Dataloaders created.\")"
      ],
      "id": "SN5G5Iz2yYZJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataloaders created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c969GhgfknZ8"
      },
      "source": [
        "### Define the model described"
      ],
      "id": "c969GhgfknZ8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cEmmvFtFjEl"
      },
      "source": [
        "# construct network model\n",
        "\n",
        "class FFNN_2c(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim1, hidden_dim2, vocab_size, features_dim):  \n",
        "        super(FFNN_2c, self).__init__()\n",
        "\n",
        "        # padding_idx argument makes sure that the 0-th token in the vocabulary\n",
        "        # is used for padding purposes i.e. its embedding will be a 0-vector\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        \n",
        "        self.fc_eh1 = nn.Linear(embedding_dim, hidden_dim1)\n",
        "\n",
        "        self.fc_fh2 = nn.Linear(features_dim, hidden_dim2)\n",
        "        self.fc_h2h2 = nn.Linear(hidden_dim2, hidden_dim2)\n",
        "\n",
        "        self.fc_hh = nn.Linear(hidden_dim1 + hidden_dim2, hidden_dim1)\n",
        "        self.fc_ho = nn.Linear(hidden_dim1, 1)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.6)\n",
        "    \n",
        "    def forward(self, x_sent, x_feat):\n",
        "        # x has shape (batch_size, max_sent_len)\n",
        "\n",
        "        embedded = self.embedding(x_sent)\n",
        "        sent_lens = x_sent.ne(0).sum(1, keepdims=True)\n",
        "        averaged = embedded.sum(1) / sent_lens\n",
        "\n",
        "        # pass the embedding though a layer\n",
        "        out_emb = torch.relu(self.fc_eh1(averaged))\n",
        "        out_emb = self.dropout(out_emb)\n",
        "\n",
        "        # pass the engineered features through two layers\n",
        "        out_feat = torch.relu(self.fc_fh2(x_feat))\n",
        "        out_feat = torch.relu(self.fc_h2h2(out_feat))\n",
        "        out_feat = self.dropout(out_feat)\n",
        "\n",
        "        # concatenate\n",
        "        out = torch.cat((out_emb, out_feat), dim=1)\n",
        "        out = torch.relu(self.fc_hh(out))\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        # prepare the regression output\n",
        "        out = self.fc_ho(out)\n",
        "        out = torch.clamp(out, max=3.0)\n",
        "        return out"
      ],
      "id": "9cEmmvFtFjEl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRvnWe8dlA6z"
      },
      "source": [
        "### Define the hyper-parameters, the model, the optimizer and the loss"
      ],
      "id": "KRvnWe8dlA6z"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQXR8zwmFjEm"
      },
      "source": [
        "# run model on training dataset\n",
        "\n",
        "EPOCHS = 15\n",
        "LRATE = 0.0004 # 0.001\n",
        "EMBEDDING_DIM = 10\n",
        "FEATURES_DIM = 11\n",
        "HIDDEN_DIM1 = 40\n",
        "HIDDEN_DIM2 = 6\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model_2c = FFNN_2c(EMBEDDING_DIM, HIDDEN_DIM1, HIDDEN_DIM2, len(word2idx), FEATURES_DIM)\n",
        "\n",
        "model_2c.to(device)\n",
        "model_2c.train()\n",
        "\n",
        "optimizer = optim.Adam(model_2c.parameters(), lr=LRATE)\n",
        "\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "loss_fn = loss_fn.to(device)"
      ],
      "id": "kQXR8zwmFjEm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMN0mT_8lLNh"
      },
      "source": [
        "#### Train the model"
      ],
      "id": "NMN0mT_8lLNh"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3n7izYIwDl1",
        "outputId": "e26bf969-de45-4229-d82e-9cc75673a089"
      },
      "source": [
        "train(train_loader, validation_loader, model_2c, EPOCHS)"
      ],
      "id": "F3n7izYIwDl1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model.\n",
            "| Epoch: 01 | Train Loss: 0.576 | Train MSE: 0.576 | Train RMSE: 0.759 |         Val. Loss: 0.353 | Val. MSE: 0.353 |  Val. RMSE: 0.594 |\n",
            "| Epoch: 02 | Train Loss: 0.434 | Train MSE: 0.434 | Train RMSE: 0.658 |         Val. Loss: 0.339 | Val. MSE: 0.339 |  Val. RMSE: 0.583 |\n",
            "| Epoch: 03 | Train Loss: 0.410 | Train MSE: 0.410 | Train RMSE: 0.640 |         Val. Loss: 0.340 | Val. MSE: 0.340 |  Val. RMSE: 0.583 |\n",
            "| Epoch: 04 | Train Loss: 0.396 | Train MSE: 0.396 | Train RMSE: 0.629 |         Val. Loss: 0.336 | Val. MSE: 0.336 |  Val. RMSE: 0.580 |\n",
            "| Epoch: 05 | Train Loss: 0.381 | Train MSE: 0.381 | Train RMSE: 0.617 |         Val. Loss: 0.335 | Val. MSE: 0.335 |  Val. RMSE: 0.579 |\n",
            "| Epoch: 06 | Train Loss: 0.374 | Train MSE: 0.374 | Train RMSE: 0.611 |         Val. Loss: 0.331 | Val. MSE: 0.331 |  Val. RMSE: 0.575 |\n",
            "| Epoch: 07 | Train Loss: 0.365 | Train MSE: 0.365 | Train RMSE: 0.604 |         Val. Loss: 0.334 | Val. MSE: 0.334 |  Val. RMSE: 0.578 |\n",
            "| Epoch: 08 | Train Loss: 0.360 | Train MSE: 0.360 | Train RMSE: 0.600 |         Val. Loss: 0.331 | Val. MSE: 0.331 |  Val. RMSE: 0.575 |\n",
            "| Epoch: 09 | Train Loss: 0.357 | Train MSE: 0.357 | Train RMSE: 0.597 |         Val. Loss: 0.329 | Val. MSE: 0.329 |  Val. RMSE: 0.573 |\n",
            "| Epoch: 10 | Train Loss: 0.353 | Train MSE: 0.353 | Train RMSE: 0.594 |         Val. Loss: 0.329 | Val. MSE: 0.329 |  Val. RMSE: 0.573 |\n",
            "| Epoch: 11 | Train Loss: 0.348 | Train MSE: 0.348 | Train RMSE: 0.590 |         Val. Loss: 0.328 | Val. MSE: 0.328 |  Val. RMSE: 0.572 |\n",
            "| Epoch: 12 | Train Loss: 0.344 | Train MSE: 0.344 | Train RMSE: 0.587 |         Val. Loss: 0.328 | Val. MSE: 0.328 |  Val. RMSE: 0.573 |\n",
            "| Epoch: 13 | Train Loss: 0.344 | Train MSE: 0.344 | Train RMSE: 0.586 |         Val. Loss: 0.328 | Val. MSE: 0.328 |  Val. RMSE: 0.573 |\n",
            "| Epoch: 14 | Train Loss: 0.337 | Train MSE: 0.337 | Train RMSE: 0.581 |         Val. Loss: 0.329 | Val. MSE: 0.329 |  Val. RMSE: 0.574 |\n",
            "| Epoch: 15 | Train Loss: 0.338 | Train MSE: 0.338 | Train RMSE: 0.581 |         Val. Loss: 0.329 | Val. MSE: 0.329 |  Val. RMSE: 0.574 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kmz3RHplOU_"
      },
      "source": [
        "#### Verify performance of the final model on the training set (compared to mean baseline)"
      ],
      "id": "0kmz3RHplOU_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K--yw-oAFjEt",
        "outputId": "49515e26-6f85-4500-8afd-fc015a571644"
      },
      "source": [
        "mean_value = 0.9355712114933001\n",
        "\n",
        "# make predictions\n",
        "train_predictions = []\n",
        "model_perf = 0\n",
        "mean_perf = 0\n",
        "true_labels = []\n",
        "with torch.no_grad():\n",
        "    for batch in train_loader:\n",
        "        # add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        # unzip\n",
        "        input_sent, input_feat, targets = batch\n",
        "        # predict (forward pass)\n",
        "        pred = model_2c(input_sent, input_feat)\n",
        "        train_predictions += [pred]\n",
        "        true_labels += [targets]\n",
        "\n",
        "        mean_predictions = torch.ones_like(pred) * mean_value\n",
        "        mean_predictions = mean_predictions.to(device)\n",
        "\n",
        "        # for the model\n",
        "        # get scores\n",
        "        pred = pred.squeeze(1)\n",
        "        train_loss = loss_fn(pred, targets)\n",
        "\n",
        "        # We get the mse\n",
        "        pred, trg = pred.detach().cpu().numpy(), targets.detach().cpu().numpy()\n",
        "        sse, __ = model_performance(pred, trg)\n",
        "        model_perf += sse\n",
        "\n",
        "        # for the mean prediction\n",
        "        \n",
        "        # get scores\n",
        "        mean_predictions = mean_predictions.squeeze(1)\n",
        "        mean_loss = loss_fn(mean_predictions, targets)\n",
        "\n",
        "        # We get the mse\n",
        "        pred_mean, trg_mean = mean_predictions.detach().cpu().numpy(), targets.detach().cpu().numpy()\n",
        "        sse_mean, __ = model_performance(pred_mean, trg_mean)\n",
        "        mean_perf += sse_mean\n",
        "\n",
        "\n",
        "train_predictions = torch.cat(train_predictions, dim=0)\n",
        "true_labels = torch.cat(true_labels, dim=0).unsqueeze(1)\n",
        "check_values = torch.cat((train_predictions, true_labels), dim=1)\n",
        "print(\"Performances : --- Model : {} --- --- Mean predictor : {} ---\".format(model_perf, mean_perf))\n",
        "print(\"Values : \", check_values)"
      ],
      "id": "K--yw-oAFjEt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performances : --- Model : 3080.504093170166 --- --- Mean predictor : 3287.509463787079 ---\n",
            "Values :  tensor([[0.9391, 1.0000],\n",
            "        [0.7741, 0.2000],\n",
            "        [0.9754, 1.2000],\n",
            "        ...,\n",
            "        [0.9690, 1.4000],\n",
            "        [0.9749, 1.4000],\n",
            "        [0.8969, 0.2000]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKw-QQGRlYS4"
      },
      "source": [
        "#### Verify performance of the final model on the validation set (compared to mean baseline)"
      ],
      "id": "WKw-QQGRlYS4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x71R-0fLFjEt",
        "outputId": "2ea429e0-287e-45d1-c4ab-33239c09ed3d"
      },
      "source": [
        "# make predictions\n",
        "\n",
        "mean_value = 0.9355712114933001\n",
        "validation_predictions = []\n",
        "model_perf = 0\n",
        "mean_perf = 0\n",
        "true_labels = []\n",
        "with torch.no_grad():\n",
        "    for batch in validation_loader:\n",
        "        # add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        # unzip\n",
        "        input_sent, input_feat, targets = batch\n",
        "        # predict (forward pass)\n",
        "        pred = model_2c(input_sent, input_feat)\n",
        "        validation_predictions += [pred]\n",
        "        true_labels += [targets]\n",
        "\n",
        "        mean_predictions = torch.ones_like(pred) * mean_value\n",
        "        mean_predictions = mean_predictions.to(device)\n",
        "\n",
        "        # for the model\n",
        "        # get scores\n",
        "        pred = pred.squeeze(1)\n",
        "        validation_loss = loss_fn(pred, targets)\n",
        "\n",
        "        # We get the mse\n",
        "        pred, trg = pred.detach().cpu().numpy(), targets.detach().cpu().numpy()\n",
        "        sse, __ = model_performance(pred, trg)\n",
        "        model_perf += sse\n",
        "\n",
        "        # for the mean prediction\n",
        "        \n",
        "        # get scores\n",
        "        mean_predictions = mean_predictions.squeeze(1)\n",
        "        mean_loss = loss_fn(mean_predictions, targets)\n",
        "\n",
        "        # We get the mse\n",
        "        pred_mean, trg_mean = mean_predictions.detach().cpu().numpy(), targets.detach().cpu().numpy()\n",
        "        sse_mean, __ = model_performance(pred_mean, trg_mean)\n",
        "        mean_perf += sse_mean\n",
        "\n",
        "\n",
        "validation_predictions = torch.cat(validation_predictions, dim=0)\n",
        "true_labels = torch.cat(true_labels, dim=0).unsqueeze(1)\n",
        "check_values = torch.cat((validation_predictions, true_labels), dim=1)\n",
        "print(\"Performances : --- Model : {} --- --- Mean predictor : {} ---\".format(model_perf, mean_perf))\n",
        "print(\"Values : \", check_values)"
      ],
      "id": "x71R-0fLFjEt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performances : --- Model : 796.3753771781921 --- --- Mean predictor : 809.26771068573 ---\n",
            "Values :  tensor([[0.8796, 1.0000],\n",
            "        [1.2529, 0.8000],\n",
            "        [0.9884, 0.6000],\n",
            "        ...,\n",
            "        [0.9092, 1.4000],\n",
            "        [0.8978, 1.4000],\n",
            "        [1.1957, 0.6000]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mwWMcPnlbrB"
      },
      "source": [
        "### Launch prediction on the test set"
      ],
      "id": "9mwWMcPnlbrB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3HjO9WbFjEu",
        "outputId": "8abce20b-654c-491f-eb7b-5ffcbbbc8293"
      },
      "source": [
        "# get the data\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# prepare input for embedding\n",
        "test_tokenized_corpus = get_tokenized_corpus(test_df[\"original\"].str.cat(test_df[\"edit\"], sep=\" \").tolist())\n",
        "test_sentence = get_model_inputs(test_tokenized_corpus, word2idx)\n",
        "\n",
        "# transforms the headlines\n",
        "test_df = create_engineered_features(test_df, punctuations, sex_words)\n",
        "test_features = test_df[columns].values\n",
        "\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "test_features = torch.tensor(test_features, dtype=torch.float32)\n",
        "test_data = torch.utils.data.TensorDataset(test_sentence, test_features)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, shuffle=False, batch_size=BATCH_SIZE)\n",
        "\n",
        "\n",
        "# make predictions\n",
        "test_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        # add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        # unzip\n",
        "        input_sent, input_feat = batch\n",
        "        # predict (forward pass)\n",
        "        pred = model_2c(input_sent, input_feat)\n",
        "        test_predictions += [pred]\n",
        "\n",
        "test_predictions = torch.cat(test_predictions, dim=0)\n",
        "test_predictions"
      ],
      "id": "A3HjO9WbFjEu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8626],\n",
              "        [1.0501],\n",
              "        [0.8488],\n",
              "        ...,\n",
              "        [0.9714],\n",
              "        [0.9008],\n",
              "        [0.9115]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYW5R-4QlsJY"
      },
      "source": [
        ""
      ],
      "id": "UYW5R-4QlsJY",
      "execution_count": null,
      "outputs": []
    }
  ]
}