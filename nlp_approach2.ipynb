{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "nlp_approach1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import libraries\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
<<<<<<< HEAD
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from torch.utils.data import Dataset, random_split\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import codecs"
=======
        "from sklearn.model_selection import train_test_split"
      ],
      "id": "cRO6hDwZY76Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0905KiZZQsW",
        "outputId": "7066000b-01a5-4f73-b4cc-bcc4d59d463b"
      },
      "source": [
        "!pip install transformers\r\n",
        "from transformers import BertTokenizer, BertModel, AdamW"
      ],
      "id": "J0905KiZZQsW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set random seed and device\n",
        "\n",
        "SEED = 1\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
<<<<<<< HEAD
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
=======
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "print(\"Use : \", device)\n"
      ],
      "id": "45guyUHNY76U",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use :  cuda:0\n"
          ],
          "name": "stdout"
        }
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load datasets\n",
        "\n",
<<<<<<< HEAD
        "train_df = pd.read_csv('train.csv')\n",
        "dev_df = pd.read_csv('dev.csv')"
      ]
=======
        "    for epoch in range(1, number_epoch + 1):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        epoch_sse = 0\n",
        "        no_observations = 0  # Observations used for training so far\n",
        "\n",
        "        for batch in train_iter:\n",
        "            # add batch to GPU\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            # unzip\n",
        "            input_ids, input_masks, input_toktypes, targets = batch\n",
        "            # predict (forward pass)\n",
        "            predictions = model(input_ids, input_masks, input_toktypes)\n",
        "            predictions = predictions.squeeze(1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss = loss_fn(predictions, targets)\n",
        "\n",
        "            sse, __ = model_performance(predictions.detach().cpu().numpy(), targets.detach().cpu().numpy())\n",
        "\n",
        "            # Backpropagate and optimize\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            # update metrics\n",
        "            no_observations = no_observations + targets.shape[0]\n",
        "            epoch_loss += loss.item() * targets.shape[0]\n",
        "            epoch_sse += sse\n",
        "\n",
        "        valid_loss, valid_mse, __, __ = eval(validation_iter, model)\n",
        "\n",
        "        epoch_loss, epoch_mse = epoch_loss / no_observations, epoch_sse / no_observations\n",
        "        print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train MSE: {epoch_mse:.2f} | Train RMSE: {epoch_mse**0.5:.2f} | \\\n",
        "        Val. Loss: {valid_loss:.2f} | Val. MSE: {valid_mse:.2f} |  Val. RMSE: {valid_mse**0.5:.2f} |')"
      ],
      "id": "huupYxqXY76Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr11jwCmY76Z"
      },
      "source": [
        "# We evaluate performance on our dev set\n",
        "def eval(data_iter, model):\n",
        "    \"\"\"\n",
        "    Evaluating model performance on the dev set\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_sse = 0\n",
        "    pred_all = []\n",
        "    trg_all = []\n",
        "    no_observations = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_iter:\n",
        "            # add batch to GPU\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            # unzip\n",
        "            input_ids, input_masks, input_toktypes, targets = batch\n",
        "            # predict (forward pass)\n",
        "            predictions = model(input_ids, input_masks, input_toktypes)\n",
        "\n",
        "            predictions = predictions.squeeze(1)\n",
        "            loss = loss_fn(predictions, targets)\n",
        "\n",
        "            # We get the mse\n",
        "            pred, trg = predictions.detach().cpu().numpy(), targets.detach().cpu().numpy()\n",
        "            sse, __ = model_performance(pred, trg)\n",
        "\n",
        "            no_observations = no_observations + targets.shape[0]\n",
        "            epoch_loss += loss.item() * targets.shape[0]\n",
        "            epoch_sse += sse\n",
        "            pred_all.extend(pred)\n",
        "            trg_all.extend(trg)\n",
        "\n",
        "    return epoch_loss/no_observations, epoch_sse/no_observations, np.array(pred_all), np.array(trg_all)"
      ],
      "id": "Xr11jwCmY76Z",
      "execution_count": null,
      "outputs": []
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# How we print the model performance\n",
        "def model_performance(output, target, print_output=False):\n",
        "    \"\"\"\n",
        "    Returns SSE and MSE per batch (printing the MSE and the RMSE)\n",
        "    \"\"\"\n",
        "\n",
        "    sq_error = (output - target)**2\n",
        "\n",
        "    sse = np.sum(sq_error)\n",
        "    mse = np.mean(sq_error)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    if print_output:\n",
        "        print(f'| MSE: {mse:.2f} | RMSE: {rmse:.2f} |')\n",
        "\n",
        "    return sse, mse"
<<<<<<< HEAD
      ]
=======
      ],
      "id": "XVaiqfJcY76Z",
      "execution_count": null,
      "outputs": []
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_vocab(data):\n",
        "    \"\"\"\n",
        "    Creating a corpus of all the tokens used\n",
        "    \"\"\"\n",
        "    tokenized_corpus = [] # Let us put the tokenized corpus in a list\n",
        "\n",
        "    for sentence in data:\n",
        "\n",
        "        tokenized_sentence = []\n",
        "\n",
        "        for token in sentence.split(' '): # simplest split is\n",
        "\n",
        "            tokenized_sentence.append(token)\n",
        "\n",
        "        tokenized_corpus.append(tokenized_sentence)\n",
        "\n",
        "    # Create single list of all vocabulary\n",
        "    vocabulary = []  # Let us put all the tokens (mostly words) appearing in the vocabulary in a list\n",
        "\n",
        "    for sentence in tokenized_corpus:\n",
        "\n",
        "        for token in sentence:\n",
        "\n",
        "            if token not in vocabulary:\n",
        "\n",
        "                if True:\n",
        "                    vocabulary.append(token)\n",
        "\n",
        "    return vocabulary, tokenized_corpus"
      ]
    },
    {
      "source": [
        "# Approach 2\n",
        "## a. Given code and baseline"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "train_and_dev = train_df['edit']\n",
        "\n",
        "training_data, dev_data, training_y, dev_y = train_test_split(train_df['edit'], train_df['meanGrade'],\n",
        "                                                                        test_size=(1-train_proportion),\n",
        "                                                                        random_state=42)\n",
        "\n",
        "# We train a Tf-idf model\n",
        "count_vect = CountVectorizer(stop_words='english')\n",
        "train_counts = count_vect.fit_transform(training_data)\n",
        "transformer = TfidfTransformer().fit(train_counts)\n",
        "train_counts = transformer.transform(train_counts)\n",
        "regression_model = LinearRegression().fit(train_counts, training_y)\n",
        "\n",
        "# Train predictions\n",
        "predicted_train = regression_model.predict(train_counts)\n",
        "\n",
        "# Calculate Tf-idf using train and dev, and validate model on dev:\n",
        "test_and_test_counts = count_vect.transform(train_and_dev)\n",
        "transformer = TfidfTransformer().fit(test_and_test_counts)\n",
        "\n",
        "test_counts = count_vect.transform(dev_data)\n",
        "\n",
        "test_counts = transformer.transform(test_counts)\n",
        "\n",
        "# Dev predictions\n",
        "predicted = regression_model.predict(test_counts)\n",
        "\n",
        "# We run the evaluation:\n",
        "print(\"\\nTrain performance:\")\n",
        "sse, mse = model_performance(predicted_train, training_y, True)\n",
        "\n",
        "print(\"\\nDev performance:\")\n",
        "sse, mse = model_performance(predicted, dev_y, True)"
=======
        "# Import the data\r\n",
        "train_df = pd.read_csv('train.csv')\r\n",
        "\r\n",
        "train_df.head()"
      ],
      "id": "VRJTGVfApqfu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original</th>\n",
              "      <th>edit</th>\n",
              "      <th>grades</th>\n",
              "      <th>meanGrade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14530</td>\n",
              "      <td>France is ‘ hunting down its citizens who join...</td>\n",
              "      <td>twins</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13034</td>\n",
              "      <td>Pentagon claims 2,000 % increase in Russian tr...</td>\n",
              "      <td>bowling</td>\n",
              "      <td>33110</td>\n",
              "      <td>1.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8731</td>\n",
              "      <td>Iceland PM Calls Snap Vote as Pedophile Furor ...</td>\n",
              "      <td>party</td>\n",
              "      <td>22100</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>76</td>\n",
              "      <td>In an apparent first , Iran and Israel &lt;engage...</td>\n",
              "      <td>slap</td>\n",
              "      <td>20000</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6164</td>\n",
              "      <td>Trump was told weeks ago that Flynn misled &lt;Vi...</td>\n",
              "      <td>school</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                           original  ... grades  meanGrade\n",
              "0  14530  France is ‘ hunting down its citizens who join...  ...  10000        0.2\n",
              "1  13034  Pentagon claims 2,000 % increase in Russian tr...  ...  33110        1.6\n",
              "2   8731  Iceland PM Calls Snap Vote as Pedophile Furor ...  ...  22100        1.0\n",
              "3     76  In an apparent first , Iran and Israel <engage...  ...  20000        0.4\n",
              "4   6164  Trump was told weeks ago that Flynn misled <Vi...  ...      0        0.0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "# baseline for the task\n",
        "\n",
        "pred_baseline = torch.zeros(len(dev_y)) + np.mean(training_y)\n",
        "print(\"\\nBaseline performance:\")\n",
        "sse, mse = model_performance(pred_baseline, dev_y, True)"
=======
        "train_df[\"original\"][0]"
      ],
      "id": "6ITnT1Duq7Gr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'France is ‘ hunting down its citizens who joined <Isis/> ’ without trial in Iraq'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_qUgPYzpMPB"
      },
      "source": [
        "## b. BERT-like model\n",
        "First attempt at training a BERT-like transformer model. We thought we would create a model from scratch using the given libraries, train it on a smaller but dedicated dataset, and implement it in place of BERT. We went for a RoBERTa-like model. All elements of the model are identified with the suffix \"_2b\"\n",
        "\n",
        "Largely inspired by https://towardsdatascience.com/transformers-retraining-roberta-base-using-the-roberta-mlm-procedure-7422160d5764 "
      ],
      "id": "Q_qUgPYzpMPB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "# mount google drive to work in colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "!mkdir \"/content/drive/My Drive/abc/aBERTc2\""
      ]
=======
        "import re\r\n",
        "def pre_process_headlines(input_df):\r\n",
        "    \"\"\"\r\n",
        "    Create the new headline and remove the tags\r\n",
        "    \"\"\"\r\n",
        "    input_df[\"new\"] = input_df.apply(\r\n",
        "        lambda x: re.sub(r\"<.+/>\", x[\"edit\"], x[\"original\"]), axis=1\r\n",
        "    )\r\n",
        "\r\n",
        "    input_df[\"original\"] = input_df[\"original\"].str.replace(r\"<(.+)/>\", \"\\g<1>\")\r\n",
        "    return input_df\r\n",
        "\r\n",
        "train_df = pre_process_headlines(train_df)"
      ],
      "id": "FrDhyyUCp6-U",
      "execution_count": null,
      "outputs": []
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "# extract txt from original csv dataset\n",
        "# commented out as only needed the first time\n",
        "\n",
        "# import pandas as pd\n",
        "# abcnews = pd.read_csv('/content/drive/My Drive/abc/abcnews.csv')\n",
        "\n",
        "# with open(\"/content/drive/My Drive/abc/abcheads.txt\", \"a\") as file:\n",
        "#   for line in abcnews['headline_text']:\n",
        "#     line += \"\\n\"\n",
        "#     file.write(line)"
=======
        "print(train_df[\"original\"][0])\r\n",
        "print(train_df[\"new\"][0])"
      ],
      "id": "RNx-XL_Lqn3A",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "France is ‘ hunting down its citizens who joined Isis ’ without trial in Iraq\n",
            "France is ‘ hunting down its citizens who joined twins ’ without trial in Iraq\n"
          ],
          "name": "stdout"
        }
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "# import premade tokenizer (byte-level BPE)\n",
        "\n",
        "from transformers import RobertaTokenizer\n",
        "\n",
        "tokenizer_2b = RobertaTokenizer.from_pretrained('roberta-base')"
=======
        "train_df[\"new\"][0]"
      ],
      "id": "bss61jla7gJj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'France is ‘ hunting down its citizens who joined twins ’ without trial in Iraq'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "# prepare txt dataset with tokenizer\n",
        "\n",
        "from transformers import LineByLineTextDataset\n",
        "\n",
        "dataset_2b = LineByLineTextDataset(\n",
        "    tokenizer=tokenizer_2b,\n",
        "    file_path=\"/content/drive/My Drive/abc/abcheads.txt\",\n",
        "    block_size=128,\n",
        ")"
=======
        "train_df.head()"
      ],
      "id": "2pFTXze5sC4C",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original</th>\n",
              "      <th>edit</th>\n",
              "      <th>grades</th>\n",
              "      <th>meanGrade</th>\n",
              "      <th>new</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14530</td>\n",
              "      <td>France is ‘ hunting down its citizens who join...</td>\n",
              "      <td>twins</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>France is ‘ hunting down its citizens who join...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13034</td>\n",
              "      <td>Pentagon claims 2,000 % increase in Russian tr...</td>\n",
              "      <td>bowling</td>\n",
              "      <td>33110</td>\n",
              "      <td>1.6</td>\n",
              "      <td>Pentagon claims 2,000 % increase in Russian tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8731</td>\n",
              "      <td>Iceland PM Calls Snap Vote as Pedophile Furor ...</td>\n",
              "      <td>party</td>\n",
              "      <td>22100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Iceland PM Calls Snap Vote as Pedophile Furor ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>76</td>\n",
              "      <td>In an apparent first , Iran and Israel engage ...</td>\n",
              "      <td>slap</td>\n",
              "      <td>20000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>In an apparent first , Iran and Israel slap ea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6164</td>\n",
              "      <td>Trump was told weeks ago that Flynn misled Vic...</td>\n",
              "      <td>school</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Trump was told weeks ago that Flynn misled sch...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ...                                                new\n",
              "0  14530  ...  France is ‘ hunting down its citizens who join...\n",
              "1  13034  ...  Pentagon claims 2,000 % increase in Russian tr...\n",
              "2   8731  ...  Iceland PM Calls Snap Vote as Pedophile Furor ...\n",
              "3     76  ...  In an apparent first , Iran and Israel slap ea...\n",
              "4   6164  ...  Trump was told weeks ago that Flynn misled sch...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "# prepare data collator (speeds up things, not sure what)\n",
        "\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator_2b = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer_2b, mlm=True, mlm_probability=0.15\n",
        ")"
      ]
=======
        "# train_df"
      ],
      "id": "r3P-5Agkhd1c",
      "execution_count": null,
      "outputs": []
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create Roberta model from scratch, just prepare config\n",
        "\n",
        "from transformers import RobertaConfig, RobertaForMaskedLM\n",
        "\n",
        "config_2b = RobertaConfig(\n",
        "    vocab_size=52_000,\n",
        "    max_position_embeddings=514,\n",
        "    num_attention_heads=12,\n",
        "    num_hidden_layers=6,\n",
        "    type_vocab_size=1,\n",
        ")\n",
        "\n",
        "model_2b = RobertaForMaskedLM(config=config_2b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "# set up training configurations\n",
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args_2b = TrainingArguments(\n",
        "    output_dir=\"/content/drive/My Drive/abc/aBERTc2\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=64,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        "    seed=1\n",
        ")\n",
        "\n",
        "trainer_2b = Trainer(\n",
        "    model=model_2b,\n",
        "    args=training_args_2b,\n",
        "    data_collator=data_collator_2b,\n",
        "    train_dataset=dataset_2b\n",
        ")"
      ]
=======
        "# max len in our dataset is 35\r\n",
        "MAX_LEN = 42\r\n",
        "concat = True\r\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\r\n",
        "\r\n",
        "def tokenize_from_dataframe(input_df, tokenizer, max_len=42, concat=False):\r\n",
        "    \"\"\"\r\n",
        "    Get the headline, tokenize, create the attention mask and return.\r\n",
        "    \"\"\"\r\n",
        "    if concat:\r\n",
        "        max_len = 2 * max_len\r\n",
        "        headlines = input_df[\"original\"].values + \" [SEP] \" + input_df[\"new\"].values\r\n",
        "    else:\r\n",
        "        headlines = input_df[\"new\"].values\r\n",
        "\r\n",
        "    # create input ids\r\n",
        "    input_ids = [tokenizer.encode(headline, add_special_tokens=True, max_length=max_len, padding='max_length') for headline in headlines]\r\n",
        "\r\n",
        "    ## Create attention and segment mask\r\n",
        "    attention_masks = []\r\n",
        "    token_type_ids = []\r\n",
        "    for seq in input_ids:\r\n",
        "        attention_mask = [float(i>0) for i in seq]\r\n",
        "        attention_mask = []\r\n",
        "        segment_mask = []\r\n",
        "        seen_sep = False\r\n",
        "        for i in seq:\r\n",
        "            attention_mask += [float(i>0)]\r\n",
        "            segment_mask += [int(seen_sep)]\r\n",
        "            if i == 102:\r\n",
        "                seen_sep = True\r\n",
        "        attention_masks += [attention_mask]\r\n",
        "        token_type_ids += [segment_mask]\r\n",
        "\r\n",
        "    ## Create a mask of 1 for all input tokens and 0 for all padding tokens\r\n",
        "    #attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\r\n",
        "\r\n",
        "    return input_ids, attention_masks, token_type_ids\r\n",
        "\r\n",
        "labels = train_df[\"meanGrade\"].values\r\n",
        "input_ids, attention_masks, token_type_ids = tokenize_from_dataframe(train_df, tokenizer, MAX_LEN, concat)"
      ],
      "id": "E6J0_uKH20FU",
      "execution_count": null,
      "outputs": []
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "# verify model parameters ~ 84M\n",
        "\n",
        "model_2b.num_parameters()"
=======
        "labels.mean()"
      ],
      "id": "imK19U8Mx2Cx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9355712114933001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "# train and save trained model\n",
        "\n",
        "trainer_2b.train()\n",
        "trainer_2b.save_model(\"/content/drive/My Drive/abc/aBERTc2\")"
      ]
=======
        "#input_ids[0], input_ids[0][0]"
      ],
      "id": "8fVtRO3WLb_9",
      "execution_count": null,
      "outputs": []
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "# sanity check on model performance\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "fill_mask = pipeline(\n",
        "    \"fill-mask\",\n",
        "    model=\"/content/drive/My Drive/abc/aBERTc2\",\n",
        "    tokenizer=\"roberta-base\"\n",
        ")\n",
        "fill_mask(\"Send these <mask> back!\")"
=======
        "labels, labels.dtype"
      ],
      "id": "KHavT_aaAlww",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.2, 1.6, 1. , ..., 0.6, 1.4, 0.4]), dtype('float64'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
      ]
    },
    {
      "source": [
        "At this point we tried replacing the newly trained RoBERTa model in the pipeline we had designed for Approach 1.\n",
        "\n",
        "(Follows Samy's code and explanation of what didn't work)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "## c. FFN with word embeddings\n",
        "As second attempt we tried a modified version of a 2-layered feed-forward neural networks, modified from the 2nd lab of the course. We substituted the classification layer at the top with another linear layer in order to make it appropriate for the regression. We used all the words from the original headline + the edited word, stripped of its punctuation."
      ],
<<<<<<< HEAD
      "cell_type": "markdown",
      "metadata": {}
=======
      "id": "Pg2q0Zz0VaN-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataloaders created.\n"
          ],
          "name": "stdout"
        }
      ]
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# recreate tok_corpus, word2idx and related functions, with punctuation removal\n",
        "\n",
        "re_punctuation_string = '[\\s,/.\\'<>]'\n",
        "\n",
        "def get_tokenized_corpus(corpus):\n",
        "  tokenized_corpus = []\n",
        "\n",
        "  for sentence in corpus:\n",
        "    tokenized_sentence = []\n",
        "    for token in re.split(' ', sentence): \n",
        "      tokenized_sentence.append(token)\n",
        "    tokenized_corpus.append(tokenized_sentence)\n",
        " \n",
        "  return tokenized_corpus\n",
        "\n",
        "\n",
        "def get_word2idx(tokenized_corpus):\n",
        "  vocabulary = []\n",
        "  for sentence in tokenized_corpus:\n",
        "    for token in sentence:\n",
        "        if token not in vocabulary:\n",
        "            vocabulary.append(token)\n",
        "  \n",
        "  word2idx = {w: idx+1 for (idx, w) in enumerate(vocabulary)}\n",
        "  word2idx['<pad>'] = 0\n",
        "  \n",
        "  return word2idx\n",
        "\n",
        "\n",
        "def get_model_inputs(tokenized_corpus, word2idx, labels):\n",
        "  vectorized_sents = [[word2idx[tok] for tok in sent if tok in word2idx] for sent in tokenized_corpus]\n",
        "  sent_lengths = [len(sent) for sent in vectorized_sents]\n",
        "  max_len = max(sent_lengths)\n",
        "  sent_tensor = torch.zeros((len(vectorized_sents), max_len)).long()\n",
        "  for idx, (sent, sentlen) in enumerate(zip(vectorized_sents, sent_lengths)):\n",
        "    sent_tensor[idx, :sentlen] = torch.LongTensor(sent)\n",
        "  label_tensor = torch.FloatTensor(labels)\n",
        "  return sent_tensor, label_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# construct network model\n",
        "\n",
        "class FFNN_2c(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size):  \n",
        "        super(FFNN, self).__init__()\n",
        "\n",
        "        # padding_idx argument makes sure that the 0-th token in the vocabulary\n",
        "        # is used for padding purposes i.e. its embedding will be a 0-vector\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "        self.relu2 = nn.ReLU()  \n",
        "    \n",
        "    def forward(self, x):\n",
        "        # x has shape (batch_size, max_sent_len)\n",
        "\n",
        "        embedded = self.embedding(x)\n",
        "        sent_lens = x.ne(0).sum(1, keepdims=True)\n",
        "        averaged = embedded.sum(1) / sent_lens\n",
        "\n",
        "        out = self.fc1(averaged)\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = torch.clamp(out, max=3.0)\n",
        "        return out"
<<<<<<< HEAD
      ]
=======
      ],
      "id": "vXGqJjzAoi7K",
      "execution_count": null,
      "outputs": []
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# prepare traning set\n",
        "\n",
        "tokenized_corpus = get_tokenized_corpus(train_df[\"original\"].tolist().append(train_df[\"edit\"].tolist()))\n",
        "word2idx = get_word2idx(tokenized_corpus)\n",
        "train_sent_tensor, train_label_tensor = get_model_inputs(tokenized_corpus, word2idx, train_df['meanGrade'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run model on training dataset\n",
        "\n",
        "EPOCHS = 10\n",
        "LRATE = 0.5\n",
        "EMBEDDING_DIM = 80\n",
        "HIDDEN_DIM = 80\n",
        "\n",
        "model_2c = FFNN_2c(EMBEDDING_DIM, HIDDEN_DIM, len(word2idx))\n",
        "optimizer_2c = torch.optim.SGD(model_2c.parameters(), lr=LRATE)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "feature = train_sent_tensor\n",
        "target = train_label_tensor\n",
        "\n",
<<<<<<< HEAD
        "for epoch in range(1, EPOCHS + 1):\n",
        "  model_2c.train()\n",
        "  optimizer_2c.zero_grad()\n",
        "  \n",
        "  predictions = model_2c(feature).squeeze(1)\n",
        "  loss = loss_fn(predictions, target)\n",
        "  train_loss = loss.item()\n",
        "  \n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  \n",
        "  print(f'| Epoch: {epoch:02} | Train Loss: {train_loss:.3f}')"
=======
        "loss_fn = nn.MSELoss()\n",
        "loss_fn = loss_fn.to(device)"
      ],
      "id": "hfV3bmhUY76b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model initialised.\n"
          ],
          "name": "stdout"
        }
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "# prepare validation dataset\n",
        "\n",
        "dev_tokenized_corpus = get_tokenized_corpus(dev_df[\"original\"].tolist().append(dev_df[\"edit\"].tolist()))\n",
        "dev_sent_tensor, dev_label_tensor = get_model_inputs(dev_tokenized_corpus, word2idx, dev_df['meanGrade'])"
=======
        "train(model, train_loader, validation_loader, num_epochs)"
      ],
      "id": "3Fy6DDsrjaeK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model.\n",
            "| Epoch: 01 | Train Loss: 0.44 | Train MSE: 0.44 | Train RMSE: 0.66 |         Val. Loss: 0.29 | Val. MSE: 0.29 |  Val. RMSE: 0.54 |\n",
            "| Epoch: 02 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.54 |         Val. Loss: 0.29 | Val. MSE: 0.29 |  Val. RMSE: 0.54 |\n"
          ],
          "name": "stdout"
        }
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "# optimise hyperparameters on validation set\n",
        "\n",
        "EPOCHS = 30\n",
        "LRATE = 0.5\n",
        "EMBEDDING_DIM = 50\n",
        "HIDDEN_DIM = 50\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model_2c = FFNN_2c(EMBEDDING_DIM, HIDDEN_DIM, len(word2idx))\n",
        "optimizer_2c = torch.optim.SGD(model_2c.parameters(), lr=LRATE)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "feature_train = train_sent_tensor\n",
        "target_train = train_label_tensor\n",
        "\n",
        "feature_valid = dev_sent_tensor\n",
        "target_valid = dev_label_tensor\n",
        "\n",
        "print(f'Will train for {EPOCHS} epochs')\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "  model_2c.train()\n",
        "  optimizer_2c.zero_grad()\n",
        "  predictions = model_2c(feature_train).squeeze(1)\n",
        "\n",
        "  loss = loss_fn(predictions, target_train)\n",
        "  train_loss = loss.item()\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer_2c.step()\n",
        "  \n",
        "  model_2c.eval()\n",
        "  with torch.no_grad():\n",
        "    predictions_valid = model_2c(feature_valid).squeeze(1)\n",
        "    valid_loss = loss_fn(predictions_valid, target_valid).item()\n",
        "  \n",
        "  print(f'| Epoch: {epoch:02} | Train Loss: {train_loss:.3f} | Val. Loss: {valid_loss:.3f} |')"
=======
        "model.eval()\r\n",
        "print(\"To eval mode.\")"
      ],
      "id": "qVZQVy421wuO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "To eval mode.\n"
          ],
          "name": "stdout"
        }
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## d. Freestyle approach with handcrafter engineered features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "punctuations = '''!()-[]{};:‘’\"\\,.?@#$%^&*_~'''\n",
        "sex_words = [\"orgy\", \"dick\", \"suck\", \"underwear\", \"sex\", \"sexual\", \"massage\", \"flirt\", \"kiss\", \"ass\", \"penis\"]\n",
        "\n",
        "def create_engineered_features(train_df, punctuations, sex_words):\n",
        "    train_df[\"lower_case\"] = train_df.apply(\n",
        "            lambda x: x[\"original\"].lower(), axis=1\n",
        "        )\n",
        "    train_df[\"edit_lower\"] = train_df.apply(\n",
        "            lambda x: x[\"edit\"].lower(), axis=1\n",
        "        )\n",
        "    train_df[\"nb_words\"] = train_df.apply(\n",
        "            lambda x: len(x[\"lower_case\"].split(\" \")), axis=1\n",
        "        )\n",
        "    train_df[\"nb_caracters\"] = train_df.apply(\n",
        "            lambda x: len(x[\"lower_case\"]), axis=1\n",
        "        )\n",
        "    train_df[\"nb_ponctuations\"] = train_df.apply(\n",
        "            lambda x: sum([1 if char in punctuations else 0 for char in x[\"lower_case\"]]), axis=1\n",
        "        )\n",
        "    train_df[\"edit_position\"] = train_df.apply(\n",
        "            lambda x: x[\"lower_case\"].find(\"<\"), axis=1\n",
        "        )\n",
        "    train_df[\"edit_rel_position\"] = train_df.apply(\n",
        "            lambda x: x[\"edit_position\"]/x[\"nb_caracters\"], axis=1\n",
        "        )\n",
        "    train_df[\"len_edit\"] = train_df.apply(\n",
        "            lambda x: len(x[\"edit_lower\"]), axis=1\n",
        "        )\n",
        "    # i need trump\n",
        "    train_df[\"trump_in_original\"] = train_df.apply(\n",
        "            lambda x: float(x[\"lower_case\"].find(\"trump\") != -1), axis=1\n",
        "        )\n",
        "    train_df[\"trump_in_edit\"] = train_df.apply(\n",
        "            lambda x: float(x[\"edit_lower\"].find(\"trump\") != -1), axis=1\n",
        "        )\n",
        "\n",
        "    # i need hair\n",
        "    train_df[\"hair_in_original\"] = train_df.apply(\n",
        "            lambda x: float(x[\"lower_case\"].find(\"hair\") != -1), axis=1\n",
        "        )\n",
        "    train_df[\"hair_in_edit\"] = train_df.apply(\n",
        "            lambda x: float(x[\"edit_lower\"].find(\"hair\") != -1), axis=1\n",
        "        )\n",
        "    train_df[\"sex_in_edit\"] = train_df.apply(\n",
        "            lambda x: float(x[\"edit_lower\"] in sex_words), axis=1\n",
        "        )\n",
        "\n",
        "    return train_df"
      ]
=======
        "mean_value = 0.9355712114933001"
      ],
      "id": "PcUl1XKW3HbG",
      "execution_count": null,
      "outputs": []
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "train_df = create_engineered_features(train_df, punctuations, sex_words)\n",
        "train_df.head()"
=======
        "torch.ones((2, 2)) * mean_value"
      ],
      "id": "DfdL5BCj7c58",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9356, 0.9356],\n",
              "        [0.9356, 0.9356]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "# extract labels and features from training set \n",
        "\n",
        "columns = [\n",
        "    \"nb_words\",\n",
        "    \"nb_caracters\",\n",
        "    \"nb_ponctuations\",\n",
        "    \"edit_position\",\n",
        "    \"edit_rel_position\",\n",
        "    \"len_edit\",\t\"trump_in_original\",\n",
        "    \"trump_in_edit\",\n",
        "    \"hair_in_original\",\n",
        "    \"hair_in_edit\",\n",
        "    \"sex_in_edit\"\n",
        "    ]\n",
        "    \n",
        "features = train_df[columns].values\n",
        "labels = train_df.meanGrade.values"
=======
        "# make predictions\r\n",
        "train_predictions = []\r\n",
        "model_perf = 0\r\n",
        "mean_perf = 0\r\n",
        "true_labels = []\r\n",
        "with torch.no_grad():\r\n",
        "    for batch in train_loader:\r\n",
        "        # add batch to GPU\r\n",
        "        batch = tuple(t.to(device) for t in batch)\r\n",
        "        # unzip\r\n",
        "        input_ids, input_masks, input_toktypes, targets = batch\r\n",
        "        # predict (forward pass)\r\n",
        "        pred = model(input_ids, input_masks, input_toktypes)\r\n",
        "        train_predictions += [pred]\r\n",
        "        true_labels += [targets]\r\n",
        "\r\n",
        "        mean_predictions = torch.ones_like(pred) * mean_value\r\n",
        "        mean_predictions = mean_predictions.to(device)\r\n",
        "\r\n",
        "        # for the model\r\n",
        "        # get scores\r\n",
        "        pred = pred.squeeze(1)\r\n",
        "        train_loss = loss_fn(pred, targets)\r\n",
        "\r\n",
        "        # We get the mse\r\n",
        "        pred, trg = pred.detach().cpu().numpy(), targets.detach().cpu().numpy()\r\n",
        "        sse, __ = model_performance(pred, trg)\r\n",
        "        model_perf += sse\r\n",
        "\r\n",
        "        # for the mean prediction\r\n",
        "        \r\n",
        "        # get scores\r\n",
        "        mean_predictions = mean_predictions.squeeze(1)\r\n",
        "        mean_loss = loss_fn(mean_predictions, targets)\r\n",
        "\r\n",
        "        # We get the mse\r\n",
        "        pred_mean, trg_mean = mean_predictions.detach().cpu().numpy(), targets.detach().cpu().numpy()\r\n",
        "        sse_mean, __ = model_performance(pred_mean, trg_mean)\r\n",
        "        mean_perf += sse_mean\r\n",
        "\r\n",
        "\r\n",
        "train_predictions = torch.cat(train_predictions, dim=0)\r\n",
        "true_labels = torch.cat(true_labels, dim=0).unsqueeze(1)\r\n",
        "check_values = torch.cat((train_predictions, true_labels), dim=1)\r\n",
        "print(\"Performances : --- Model : {} --- --- Mean predictor : {} ---\".format(model_perf, mean_perf))\r\n",
        "print(\"Values : \", check_values)"
      ],
      "id": "nHcTz9cB9MiH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performances : --- Model : 2456.2369027137756 --- --- Mean predictor : 3287.50945186615 ---\n",
            "Values :  tensor([[0.6197, 0.6000],\n",
            "        [1.0415, 0.8000],\n",
            "        [0.8809, 0.4000],\n",
            "        ...,\n",
            "        [0.7812, 1.0000],\n",
            "        [0.6773, 0.2000],\n",
            "        [1.4641, 1.6000]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "# prepare the validation set\n",
        "\n",
        "dev_df = pd.read_csv('dev.csv')\n",
        "dev_df = create_engineered_features(dev_df, punctuations, sex_words)\n",
        "dev_inputs = dev_df[columns].values\n",
        "dev_labels = dev_df['meanGrade'].values"
=======
        "print((2645 - 2020)/2645, (642 - 561)/642)\r\n",
        "print((2614 - 2002)/2614, (673-598)/673)\r\n",
        "print(\"With new version\")\r\n",
        "print((2634 - 2267)/2634, (653-634)/653)\r\n",
        "print((2667 - 1809)/2667, (619-586)/619)\r\n",
        "print((2651 - 1787)/2651, (635-555)/635)\r\n",
        "print((2621 - 1920)/2621, (666-573)/666)\r\n",
        "print((3287 - 2415)/3287, (809-697)/809)"
      ],
      "id": "xb8EfJNWGbiD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.23629489603024575 0.1261682242990654\n",
            "0.234123947972456 0.11144130757800892\n",
            "With new version\n",
            "0.13933181473044798 0.02909647779479326\n",
            "0.3217097862767154 0.05331179321486268\n",
            "0.32591474915126367 0.12598425196850394\n",
            "0.26745516978252576 0.13963963963963963\n",
            "0.26528749619714026 0.138442521631644\n"
          ],
          "name": "stdout"
        }
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "# create dataloaders\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_inputs = torch.tensor(features, dtype=torch.float32)\n",
        "train_labels = torch.tensor(labels, dtype=torch.float32)\n",
        "\n",
        "validation_inputs = torch.tensor(dev_inputs, dtype=torch.float32)\n",
        "validation_labels = torch.tensor(dev_labels, dtype=torch.float32)\n",
        "\n",
        "train_data = torch.utils.data.TensorDataset(train_inputs, train_labels)\n",
        "dev_data = torch.utils.data.TensorDataset(validation_inputs, validation_labels)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE)\n",
        "validation_loader = torch.utils.data.DataLoader(dev_data, shuffle=False, batch_size=BATCH_SIZE)\n",
        "\n",
        "print(\"Dataloaders created.\")"
=======
        "# make predictions\r\n",
        "validation_predictions = []\r\n",
        "model_perf = 0\r\n",
        "mean_perf = 0\r\n",
        "true_labels = []\r\n",
        "with torch.no_grad():\r\n",
        "    for batch in validation_loader:\r\n",
        "        # add batch to GPU\r\n",
        "        batch = tuple(t.to(device) for t in batch)\r\n",
        "        # unzip\r\n",
        "        input_ids, input_masks, input_toktypes, targets = batch\r\n",
        "        # predict (forward pass)\r\n",
        "        pred = model(input_ids, input_masks, input_toktypes)\r\n",
        "        validation_predictions += [pred]\r\n",
        "        true_labels += [targets]\r\n",
        "\r\n",
        "        mean_predictions = torch.ones_like(pred) * mean_value\r\n",
        "        mean_predictions = mean_predictions.to(device)\r\n",
        "\r\n",
        "        # for the model\r\n",
        "        # get scores\r\n",
        "        pred = pred.squeeze(1)\r\n",
        "        validation_loss = loss_fn(pred, targets)\r\n",
        "\r\n",
        "        # We get the mse\r\n",
        "        pred, trg = pred.detach().cpu().numpy(), targets.detach().cpu().numpy()\r\n",
        "        sse, __ = model_performance(pred, trg)\r\n",
        "        model_perf += sse\r\n",
        "\r\n",
        "        # for the mean prediction\r\n",
        "        \r\n",
        "        # get scores\r\n",
        "        mean_predictions = mean_predictions.squeeze(1)\r\n",
        "        mean_loss = loss_fn(mean_predictions, targets)\r\n",
        "\r\n",
        "        # We get the mse\r\n",
        "        pred_mean, trg_mean = mean_predictions.detach().cpu().numpy(), targets.detach().cpu().numpy()\r\n",
        "        sse_mean, __ = model_performance(pred_mean, trg_mean)\r\n",
        "        mean_perf += sse_mean\r\n",
        "\r\n",
        "\r\n",
        "validation_predictions = torch.cat(validation_predictions, dim=0)\r\n",
        "true_labels = torch.cat(true_labels, dim=0).unsqueeze(1)\r\n",
        "check_values = torch.cat((validation_predictions, true_labels), dim=1)\r\n",
        "print(\"Performances : --- Model : {} --- --- Mean predictor : {} ---\".format(model_perf, mean_perf))\r\n",
        "print(\"Values : \", check_values)"
      ],
      "id": "zugCq5rW9WfP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performances : --- Model : 695.023973941803 --- --- Mean predictor : 809.26771068573 ---\n",
            "Values :  tensor([[0.8557, 1.0000],\n",
            "        [1.3462, 0.8000],\n",
            "        [0.5324, 0.6000],\n",
            "        ...,\n",
            "        [1.1454, 1.4000],\n",
            "        [1.2729, 1.4000],\n",
            "        [0.8481, 0.6000]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# design model architecture in torch\n",
        "\n",
        "class FFNN_2d(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(FunninessRegressor, self).__init__()\n",
        "\n",
        "        self.fc1 = torch.nn.Linear(11, 10)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = torch.nn.Linear(10, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        out = self.fc1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = torch.clamp(out, min=0.0, max=3.0)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
<<<<<<< HEAD
        "# set hyperparameters, model, optimizer and loss function\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "num_epochs = 2 #2\n",
        "learning_rate = 1.8e-6 #2e-6\n",
        "adam_eps = 1e-8\n",
        "\n",
        "model_2d = FFNN_2d()\n",
        "model_2d.to(device)\n",
        "model_2d.train()\n",
        "optimizer_2d = optim.Adam(model_2d.parameters(), lr=learning_rate, eps=adam_eps)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "loss_fn = loss_fn.to(device)"
=======
        "# get the data\r\n",
        "test_df = pd.read_csv('test.csv')\r\n",
        "# transforms the headlines\r\n",
        "test_df = pre_process_headlines(test_df)\r\n",
        "test_input_ids, test_attention_masks, test_token_type_ids = tokenize_from_dataframe(test_df, tokenizer, MAX_LEN)\r\n",
        "\r\n",
        "# maybe we should make sure that max_len was enough\r\n",
        "\r\n",
        "# convert to tensor\r\n",
        "test_inputs = torch.tensor(test_input_ids)\r\n",
        "test_masks = torch.tensor(test_attention_masks, dtype=torch.float32)\r\n",
        "test_token_type_ids = torch.tensor(test_token_type_ids, dtype=torch.long)\r\n",
        "\r\n",
        "\r\n",
        "# create \r\n",
        "test_data = torch.utils.data.TensorDataset(test_inputs, test_masks, test_token_type_ids)\r\n",
        "test_loader = torch.utils.data.DataLoader(test_data, shuffle=False, batch_size=BATCH_SIZE)\r\n",
        "\r\n",
        "# make predictions\r\n",
        "test_predictions = []\r\n",
        "with torch.no_grad():\r\n",
        "    for batch in test_loader:\r\n",
        "        # add batch to GPU\r\n",
        "        batch = tuple(t.to(device) for t in batch)\r\n",
        "        # unzip\r\n",
        "        input_ids, input_masks, input_toktypes = batch\r\n",
        "        # predict (forward pass)\r\n",
        "        pred = model(input_ids, input_masks, input_toktypes)\r\n",
        "        test_predictions += [pred]\r\n",
        "\r\n",
        "test_predictions = torch.cat(test_predictions, dim=0)\r\n",
        "test_predictions"
      ],
      "id": "yELkD3fFY76c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9626],\n",
              "        [1.0532],\n",
              "        [1.0025],\n",
              "        ...,\n",
              "        [1.1637],\n",
              "        [0.9782],\n",
              "        [0.9409]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
>>>>>>> 1412d0663e0a7c6610fcbb5cde59112d62494e1b
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train model\n",
        "\n",
        "train(model, train_loader, validation_loader, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# make predictions\n",
        "train_predictions = []\n",
        "model_perf = 0\n",
        "mean_perf = 0\n",
        "true_labels = []\n",
        "with torch.no_grad():\n",
        "    for batch in train_loader:\n",
        "        # add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        # unzip\n",
        "        input_ids, targets = batch\n",
        "        # predict (forward pass)\n",
        "        pred = model_2d(input_ids)\n",
        "        train_predictions += [pred]\n",
        "        true_labels += [targets]\n",
        "\n",
        "        mean_predictions = torch.ones_like(pred) * mean_value\n",
        "        mean_predictions = mean_predictions.to(device)\n",
        "\n",
        "        # for the model\n",
        "        # get scores\n",
        "        pred = pred.squeeze(1)\n",
        "        train_loss = loss_fn(pred, targets)\n",
        "\n",
        "        # We get the mse\n",
        "        pred, trg = pred.detach().cpu().numpy(), targets.detach().cpu().numpy()\n",
        "        sse, __ = model_performance(pred, trg)\n",
        "        model_perf += sse\n",
        "\n",
        "        # for the mean prediction\n",
        "        \n",
        "        # get scores\n",
        "        mean_predictions = mean_predictions.squeeze(1)\n",
        "        mean_loss = loss_fn(mean_predictions, targets)\n",
        "\n",
        "        # We get the mse\n",
        "        pred_mean, trg_mean = mean_predictions.detach().cpu().numpy(), targets.detach().cpu().numpy()\n",
        "        sse_mean, __ = model_performance(pred_mean, trg_mean)\n",
        "        mean_perf += sse_mean\n",
        "\n",
        "\n",
        "train_predictions = torch.cat(train_predictions, dim=0)\n",
        "true_labels = torch.cat(true_labels, dim=0).unsqueeze(1)\n",
        "check_values = torch.cat((train_predictions, true_labels), dim=1)\n",
        "print(\"Performances : --- Model : {} --- --- Mean predictor : {} ---\".format(model_perf, mean_perf))\n",
        "print(\"Values : \", check_values)X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# make predictions\n",
        "validation_predictions = []\n",
        "model_perf = 0\n",
        "mean_perf = 0\n",
        "true_labels = []\n",
        "with torch.no_grad():\n",
        "    for batch in validation_loader:\n",
        "        # add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        # unzip\n",
        "        input_ids, targets = batch\n",
        "        # predict (forward pass)\n",
        "        pred = model_2d(input_ids)\n",
        "        validation_predictions += [pred]\n",
        "        true_labels += [targets]\n",
        "\n",
        "        mean_predictions = torch.ones_like(pred) * mean_value\n",
        "        mean_predictions = mean_predictions.to(device)\n",
        "\n",
        "        # for the model\n",
        "        # get scores\n",
        "        pred = pred.squeeze(1)\n",
        "        validation_loss = loss_fn(pred, targets)\n",
        "\n",
        "        # We get the mse\n",
        "        pred, trg = pred.detach().cpu().numpy(), targets.detach().cpu().numpy()\n",
        "        sse, __ = model_performance(pred, trg)\n",
        "        model_perf += sse\n",
        "\n",
        "        # for the mean prediction\n",
        "        \n",
        "        # get scores\n",
        "        mean_predictions = mean_predictions.squeeze(1)\n",
        "        mean_loss = loss_fn(mean_predictions, targets)\n",
        "\n",
        "        # We get the mse\n",
        "        pred_mean, trg_mean = mean_predictions.detach().cpu().numpy(), targets.detach().cpu().numpy()\n",
        "        sse_mean, __ = model_performance(pred_mean, trg_mean)\n",
        "        mean_perf += sse_mean\n",
        "\n",
        "\n",
        "validation_predictions = torch.cat(validation_predictions, dim=0)\n",
        "true_labels = torch.cat(true_labels, dim=0).unsqueeze(1)\n",
        "check_values = torch.cat((validation_predictions, true_labels), dim=1)\n",
        "print(\"Performances : --- Model : {} --- --- Mean predictor : {} ---\".format(model_perf, mean_perf))\n",
        "print(\"Values : \", check_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get the data\n",
        "test_df = pd.read_csv('test.csv')\n",
        "# transforms the headlines\n",
        "test_df = create_engineered_features(test_df, punctuations, sex_words)\n",
        "test_input_ids = test_df[columns].values\n",
        "\n",
        "# convert to tensor\n",
        "test_inputs = torch.tensor(test_input_ids)\n",
        "\n",
        "# create \n",
        "test_data = torch.utils.data.TensorDataset(test_inputs)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, shuffle=False, batch_size=BATCH_SIZE)\n",
        "\n",
        "# make predictions\n",
        "test_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        # add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        # unzip\n",
        "        input_ids = batch\n",
        "        # predict (forward pass)\n",
        "        pred = model_2d(input_ids)\n",
        "        test_predictions += [pred]\n",
        "\n",
        "test_predictions = torch.cat(test_predictions, dim=0)\n",
        "test_predictions"
      ]
    }
  ]
}